{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "from typing import List, Tuple\n",
    "import toolz as tz\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.bag as db\n",
    "import dask\n",
    "import dask.array as da\n",
    "import zarr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import robust_scale\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "Using a Temporal Convolutional Neural Network on breathing audio with minimal pre-processing (just downsampling and length-normalizing).  Temporal Convnets are the general case of a class of models whose most famous example is WaveNet.  Good explanation here: https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_conv/\n",
    "\n",
    "I went with this route for a few reasons. \n",
    "\n",
    "1. I have experience with using TCNs for biomedical time series (perhaps not the best reason, but included in the spirit of full disclosure :P )\n",
    "2. As a ConvNet, it can extract very \"low level\" features. \n",
    "3. The data format has bigger memory requirements when training, but requires less pre-processing.  This is relevant since the end goal is \"Edge Prediction\" served via a Smartphone app.  It's okay if it needs a bigger machine to train if the end result is that it can serve predictions on lower-end phones.\n",
    "4. I went with the TCN over other sequence-processing Deep Learning architectures (such as various flavors of RNN) due to research indicating it performs strictly better on a number of metrics: https://arxiv.org/pdf/1803.01271.pdf  It can also take better advantage of GPUs, resulting in decreased training time, which in turn leads to easier iteration & experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_length(arr: np.array, max_len: int) -> np.array:\n",
    "    arr_len = arr.shape[0]\n",
    "    diff = max_len - arr_len\n",
    "    return np.pad(arr, (0, diff), mode=\"wrap\")\n",
    "\n",
    "def make_breath_array(\n",
    "    audio_txt_folder: pathlib.Path, file_df: pd.DataFrame\n",
    ") -> dask.array.Array:\n",
    "    files_to_use = list(audio_txt_folder.rglob(\"*.wav\"))\n",
    "    # I downsampled it to the lowest I could get it without\n",
    "    # running into DivideByZero errors.  Breathing is\n",
    "    # low-frequency\n",
    "    wav_bag = (\n",
    "        db.from_sequence(files_to_use, npartitions=8)\n",
    "        .map(lambda x: librosa.core.load(x, sr=87)[0])\n",
    "        .compute()\n",
    "    )\n",
    "\n",
    "    max_len = max(x.shape[0] for x in wav_bag)\n",
    "\n",
    "    breath_array = (\n",
    "        db.from_sequence(wav_bag, npartitions=8)\n",
    "        .map(lambda x: pad_to_length(x, max_len))\n",
    "        .to_dataframe()\n",
    "        .to_dask_array(lengths=True)\n",
    "    )\n",
    "\n",
    "    new_cols = da.stack(\n",
    "        [\n",
    "            da.from_array(file_df[\"n_breaths\"].values),\n",
    "            da.from_array((file_df[\"Diagnosis\"] == \"Healthy\").astype(np.int8).values),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return da.concatenate([breath_array, new_cols], axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature review lead me to believe that for breath data we generally want Longer recordings, and can balance that out with a lower Sampling Rate.  \n",
    "\n",
    "> In comparison with other physiological signatures (e.g., heart rate, EEG), breathing patterns usually have a narrow and low frequency bandwidth (e.g., between 0.1Hz and 0.85Hz]). In other words, it requires the collection of longer data sets to allow for a deep learning process to take place\"  \n",
    "\n",
    "from here:  https://arxiv.org/ftp/arxiv/papers/1708/1708.06026.pdf\n",
    "\n",
    "## Sampling Rate\n",
    "The rate of 87 Hz was chosen due to being the lowest I could get Librosa to do without giving me `DivideByZero` errors (that I don't fully understand) while still being well above what I'm aware of as the range of frequencies of interest for human breath.  \n",
    "\n",
    "Low sampling rates are also useful because we want to balance long recordings with with memory concerns (both for storage, and so as not to run out of memory when training).\n",
    "\n",
    "## Dask Bags\n",
    "https://tutorial.dask.org/02_bag.html\n",
    "As this is a pretty big dataset, I decided to process it with Dask.  The recordings are of different lengths, so I couldn't just put them all into a Vector - so I used Dask Bags to read them at the specifed Sampling Rate, and then pad them to the length of the longest sample.  I did this because we needed a standard size for Model Optimization and easy storage.  \n",
    "\n",
    "I padded them with the `wrap` option in NumPy's `pad` function, which\n",
    ">Pads with the wrap of the vector along the axis. The first values are used to pad the end and the end values are used to pad the beginning.\n",
    "\n",
    "I decided to do this instead of just padding with 0s because breathing, unlike speech, is cyclic.  The `reflect` or `symmetric` could probably have also been used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diagnosis_df(data_folder: pathlib.Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        data_folder.joinpath(\"patient_diagnosis.csv\"),\n",
    "        header=None,\n",
    "        names=[\"Patient\", \"Diagnosis\"],\n",
    "    ).set_index(\"Patient\")\n",
    "\n",
    "\n",
    "def make_file_df(\n",
    "    diagnosis_df: pd.DataFrame, audio_txt_folder: pathlib.Path\n",
    ") -> pd.DataFrame:\n",
    "    file_stats = [\n",
    "        get_record_stats(audio_txt_folder, x.name.split(\".\")[0])\n",
    "        for x in audio_txt_folder.glob(\"*.wav\")\n",
    "    ]\n",
    "\n",
    "    file_df = pd.DataFrame(\n",
    "        file_stats,\n",
    "        columns=[\n",
    "            \"Patient\",\n",
    "            \"Section\",\n",
    "            \"Location\",\n",
    "            \"n_channels\",\n",
    "            \"device\",\n",
    "            \"filesize\",\n",
    "            \"n_breaths\",\n",
    "        ],\n",
    "    ).assign(\n",
    "        Diagnosis=lambda x: x[\"Patient\"]\n",
    "        .astype(int)\n",
    "        .map(lambda y: diagnosis_df.loc[y, \"Diagnosis\"])\n",
    "    )\n",
    "    return file_df\n",
    "\n",
    "def get_record_stats(folder: str, file: str) -> Tuple[str, str, str, int, int]:\n",
    "    name_elems = file.split(\"_\")\n",
    "    wav_size = Path(folder).joinpath(f\"{file}.wav\").stat().st_size\n",
    "    # Count the lines, then subtract 1 cuz they end on an empty\n",
    "    n_breath_cycles = (\n",
    "        sum(1 for line in open(Path(folder).joinpath(f\"{file}.txt\"), \"r\")) - 1\n",
    "    )\n",
    "    return tuple(name_elems + [wav_size] + [n_breath_cycles])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recast the different diagnoses as simply \"Healthy/Unhealthy\", as binary classifiers are simpler and we'll need to retrain the last layer anyway.\n",
    "\n",
    "I included all the samples, including stethoscope ones, because imperfect data can still help models using Transfer Learning to learn the low-level features.  We still need \"COVID patients breathing into a microphone\" for the final training, but noisy, different data is still good to throw in. In addition, we don't have any mouth recordings anyway - the closest to our ideal would be the recordings taken with a microphone from the patient's larynx.\n",
    "Deep Learning is weird, it doesn't totally follow the \"Garbage In/Garbage Out\" principle.  Blurry pictures of cars will still help a Computer Vision algo learn to distinguish Cats from Dogs.\n",
    "\n",
    "Nothing much to say about the \"counting number of breaths\" target feature!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr\n",
    "I saved the data with the Zarr format, a very handy binary format.    \n",
    "https://pythonspeed.com/articles/mmap-vs-zarr-hdf5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_zarr(arr: dask.array.Array, folder: pathlib.Path, filename: str) -> None:\n",
    "    destination = str(Path(folder, filename))\n",
    "    da.to_zarr(arr.rechunk(), destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py_387]",
   "language": "python",
   "name": "conda-env-py_387-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
